# 并发编程

## 多线程的创建方式

1 继承Thread类（本质是实现Runnable接口）

重写run方法

start()方法是一个native方法，会启动一个新的线程，并执行run方法。

2 实现Runnable接口

3 实现Callable接口

4 线程池创建

### 多线程使用场景

上万条数据需要循环的时候，创建多个线程进行筛选。

也可以用stream流的并发执行。

## 线程的生命周期

5种状态

new：初始状态，线程被创建，还没调用start方法

Runnabled：就绪状态。

Running：运行

Blocked：阻塞

Dead：死亡

![image-20210104233634483](F:\myTest\mynote\笔记\img\并发1.png)



### 线程启动

start()方法是一个native方法，会启动一个新的线程，并执行run方法。

### 线程死亡

不要使用stop方法，因为结束线程的时候不会保证线程的资源正常释放。

interrupt,设置一个标识告诉线程可以终止了，会抛异常InterruptedWxception异常。





## Synchronized关键字

jdk1.6引入偏向锁和轻量级锁。

互斥锁



Synchronized有三种方式来加锁

1 修饰实例方法，作用于当前实例加锁，进入同步代码前要获取当前实例的锁。多个实例中不互斥

2 静态方法，作用于当前类对象加锁，

3 修饰代码块，指定加锁对象，给定对象加锁。

**锁的作用范围是由锁对象的生命周期决定的**





#### 对象在内存中的布局

在hostspot虚拟机中，对象在内存中部的存储布局，可以分三个区域：对象头，实例数据，对齐填充。

对象头分为两部分： mark word 和klass pointer

数组得对象头中由数组长度

MarkWord （4个字节）用于存储对象自身的运行时数据，哈希码GC分代年龄，锁状态标志，线程持有的锁，偏向锁线程ID，偏向锁时间戳

KlassPointer（4个字节）：类型指针，对象指向类元数据的指针。虚拟机通过这个指针来确定对象是哪个类的实例。



对象头大小：

1 . 32位系统中，class指针是4个字节，MarkWord是4个字节，对象头8个字节

2. 64系统中，class指针是8个字节，Markword是8个字节，对象头16字节
3. 63位开启指针压缩，class指针是4个字节，Markword是8个字节，对象头12个字节。数组长度表示4个字节。



### 锁的四种状态

无锁，偏向锁，轻量级锁，重量级锁



#### 偏向锁的基本原理

当一个线程访问加了同步锁的代码块时，会在对象头中存储当前线程的ID，后续这个线程进入和退出这段加了同步锁的代码块时，不需要在加锁和释放锁，。 而是直接比较对象头里面是都存储了指向当前现成的偏向锁，如果相等标识偏向锁时偏向于当前线程的，就不要再尝试获取锁。

#### 偏向锁的获取和撤销逻辑

1 首先获取锁对象的Markword，判断是否处于可偏向状态。

2 如果是可偏向状态，则通过cas操作把当前线程ID写入Markword

​	a) 如果cas成功，那么markwoird就记录线程id，接着执行同步代码块。

  b) 如果cas失败，说明由其他线程已经获得偏向锁，这种情况说明当前锁存在竞争，需要撤销已获取的偏向锁的线程，并把它持有的锁升级为轻量级锁

3 如果是已偏向状态，需要检查markword中存储的ThreadID是否等于线程的ThreadID

​	a）如果相等不需要再次获得锁，可直接执行同步代码块

​	b）如果不相等，说明当前偏向于其他线程，需要撤销偏向锁并升级到轻量级锁。

#### 偏向锁的撤销

偏向锁的撤销并不是把对象恢复到无锁可偏向状态（因为偏向锁并不存在释放的概念，锁的升级过程不可逆），而实获取偏向锁的过程中，发现cas失败也是就是存在线程竞争时，直接把偏向锁对象升级到被加了轻量级锁。

对原持有偏向锁的线程进行撤销时，原获得偏向锁的线程。

有两种情况：

1 原获得偏向锁的线程如果已经退出了临界区，也就是同步代码块执行完成了。那么这个时候会把对象有设置为无锁状态，并且争抢锁的线程可以基于cas重新偏向当前线程。

2 如果原获得偏向锁的线程的同步代码块还没执行完，处于临界区之内，这个时候会把原获得偏向锁的线程升级为轻量级锁，后继续执行同步代码块。



**可以通过jvm的UseBiasedLocking来设置开启或者关闭偏向锁**



![偏向锁](\img\偏向锁.png)





#### 轻量级锁

锁升级为轻量级锁之后，对象的Markword也会进行相应的变化，升级为轻量级锁的过程。

1 线程在自己的栈帧中创建锁记录 LockRecord

2 将锁对象的对象头中的Markword复制到线程的刚刚抢到的锁记录中。

3 将锁记录中的Owner指针指向锁对象。

4 将锁对象的对象头的Markword替换为指向锁记录的指针。



#### 自旋锁

轻量级锁在加锁过程中，用到了自旋锁

所谓自旋就是当另一个线程老来竞争时，这个线程会原地循环等待，而不是把该线程阻塞，直到那个线程释放锁之后，这个线程就可以马上获得锁，（ 消耗cpu）

默认情况下自旋次数是10次，可以通过preBlockSpin来修改



jdk1.6以后引入自适应自旋锁， 会根据前一次在同一个锁上自旋的时间以及锁的拥有者状态来决定。



#### 轻量级锁的解锁

轻量级锁的释放逻辑就是获取锁的逆向逻辑，通过cas操作把线程栈帧中的LockRecord替换回对象的Markword中。如果成功表示没有竞争。如果失败表示当前锁还存在竞争，那么轻量级锁就会膨胀为重量级锁。

![image-20210108223437464](\img\轻量级锁.png)

#### 重量级锁的基本原理

当轻量级锁膨胀为重量级锁之后，意味着只能被挂起阻塞来等待唤醒了。

#### 重量级锁的monitor

javap工具查看class文件，

monitorenter 获取锁   monitorexit退出

每一个java对象都会与一个监视器monitor关联。我们可以把它理解为一把锁。当一个线程被synchronized修饰的时候，该线程获得synchronized修饰的对象的monitor。

monitorenter表示取获取一个对象监视器。

monitorexit表示释放monitor监视器的所有权，使其他被阻塞的线程可以尝试取获取这个监视器。

monitor依赖操作系统NetuxLock（互斥锁）来实现，线程被阻塞后便进入内核调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能。

#### 重量级锁的加锁基本流程

![image-20210108224721420](\img\重量级锁.png)

### wait ，notify，notifyall

Object对象中提供wait/notify/notifyall，可以控制线程的状态。



#### 基本概念

wait：表示持有对象锁的线程A准备释放对象锁权限。释放cpu资源并进入准备状态。

notify：表示持有对象锁的线程A准备释放对象锁权限，通知jvm唤醒某个竞争该对象锁的线程X。

notifyAll：notifyAll会唤醒所有竞争同一个对象所的所有线程，当已经获得锁的线程A释放锁之后，所有被唤醒的线程都有可能获得对象锁权限。



**注意：** 这三个方法都必须在synchronized关键字所限定的作用域中调用。否则会报错。java.lang.illegalMonitorStateException 意思就是因为没有同步，所以线程对对象锁的状态是不确定的，不能调用这些方法。



偏向锁（cas乐观锁）-》轻量级锁（自旋锁）-》重量级锁（mutex锁）



线程释放锁会进入同步队列（每一个阻塞会加入到这个队列中）

wait方法线程会进入等待队列，调用notify会将线程移到同步队列。





### Volatile作用

保证可见性，防止指令重排序

可能会出现：读线程不能及时的读取到其他线程写入的最新的值。 这就是所谓的可见性
为了实现跨线程写入的内存可见性，必须使用到一些机制来实现。而 volatile 就是这样一种机制  





### 从硬件层面了解可见性

运行速度  cpu> 内存>io设备

1 cpu增加了告诉缓存

2 操作系统增加了线程，进程，通过cpu的时间片切换最大化的提升cpu利用率

3 编译器的指令优化，更合理的去利用好cpu的高速缓存 -》重排序



#### cpu高速缓存

现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中  

L1 缓存，L2缓存，L3缓存（L3是cpu共享的）

#### 什么叫缓存一致性

由于在多 CPU 种，每个线程可能会运行在不同的 CPU 内，并且每个线程拥有自己的高速缓存。 同一份数据可能会被缓存到多个 CPU 中，如果在不同 CPU 中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题  



解决方案：

1 总线锁

2 缓存锁

#### 总线锁和缓存锁

总线锁：在总线上加锁，lock信号，这个信号使其他处理器无法通过总线来访问到共享内存中的数据，总线锁吧cpu和内存之间的通信锁住，总线锁开销比较大，这个机制不合适。

优化：最好方法就是控制锁的粒度，引入缓存锁， 核心机制是基于缓存一致性协议来实现的。

#### 缓存一致性协议（cpu硬件层面）

为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有MSI，MESI，MOSI。最常见的就是MESI协议。

MESI表示缓存行四种状态，分别是

1 M(modify)表示共享数据只缓存在当前cpu缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致。

2 E（Exclusive）表示缓存的独占状态，数据之缓存在当前cpu给缓存中，并且没有被修改

3 S（Shared） 表示数据可能被多个cpu缓存，并且各个缓存中的数据和主内存数据一致。

4 I（Invalid） 表示缓存已经失效。

在MESI协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且监听其他Cache的读写操作。

缓存处于 M、 E、 S 状态都可以被读取， I 状态 CPU 只能从主存中读取数据  



MESI协议带来的问题？

![image-20210110162923261](\img\并发编程1.png)

引入storebuffer-》异步带来的可见性问题 



cpu层面提供了指令-》 内存屏障



#### cpu层面内存屏障

内存屏障和就是将storebuffers中的指令写入内存，从而使得其他访问同一共享内存的线程的可见性。

X86的memory barrier指令包括 lfence(读屏障) sfence（写屏障） mfence（全屏障）

Store Memory barrier(写屏障) 告诉处理器在写屏障之前的所有已经存储在存储缓存（store buffers）中的数据同步到主内存，简单的说就是使得写屏障之前的指令的结果对屏障之后的读或者写是可见的。

Load Memory Barrier（读屏障）处理器在读屏障之后的读操作，都在读屏障之后执行，配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的

Full Memory barrier（全屏障） 确保屏障前的内存读写操作的结果提交到内存之后，在执行屏障后的读写操作。





volatile ->lock(缓存锁)-》内存屏障-》可见性 （解决平台差异化）



### JMM

全称：Java Memory Model

导致可见性为题的根本原因： 是缓存以及重排序

JMM实际上就是提供了合理的金庸缓存以及禁止重排序的方法。

核心价值：解决可见性和有序性。



JMM属于语言层级的抽象内存模型，可以简单理解为对硬件模型的抽象，他定义了共享内存中多线程程序读写操作的行为规范，在虚拟机中把共享变量存储到内存以及内存中其取出共享变量的底层实现细节，

通过这些规则来规范对内存的读写操作从而保证指令的正确性，他解决了cpu多级缓存，处理器优化，指令重排序导致的内存访问问题，保证了并发场景下的可见性。



基于cpu层面提供的内存屏障指令以及限制编译器的重排序来解决并发问题，



JMM抽象模型： 主内存，工作内存。

主内存是所有线程共享的，一般是实例对象，静态字段，数组对象等存储在堆内存的变量。

工作内存是每个线程独占的，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成的。



java内存模型底层可以简单的认为：通过内存屏障禁止指令重排序。及时编译器根据具体的底层体系架构将这些内存屏障替换成具体的cpu指令。对于编译器而言，内存屏障将限制它所能做的重排序优化。

 volatile，编译器将在 volatile 字段的读写操作前后各插入一些内存屏障。  



#### JMM如何解决可见性有序性的问题？

JMM提供了一些禁用缓存以及禁止重排序的方法，来解决可见性和有序性问题，。volatile,Synchronized,fuinal



#### JMM如何解决一致性问题



##### 重排序问题

为了提供执行性能，编译器和处理器都会堆指令进行重排序。指令的执行顺序。

源代码->1 编译器（优化重排序）->2 指令集并行重排序 ->3 内存系统重排序-> 4最终执行的指令序列

2 和3属于处理器重排序

编译器的重排序：JMM提供了禁止特性类型的编译器重排序

处理器重排序：JMM会要求编译器生成指令时，回插入内存屏障来禁止处理器重排序。





##### 不是所有程序都会重排序

数据依赖规则。as-if-serial

不管怎么排序，对于单线程的执行结果不能变。



#### JMM层面的内存屏障

编译器级别（语言级别的内存屏障）和cpu层面（内存屏障）

在JMM中内存屏障分为四类：

Loadload Barriers   load1;loadload;load2 确保load1数据的装在优先于load2所有指令

storestore Barrier  store1;storestore;store2   

LoadStore Barrier:

StoreLoadBarrier:



### HappenBefore

他的意思就是前一个操作对于后续操作是可见的。所以他是一种表达多个线程之间对于内存的可见性。


可见性的保证    除了volatile以外，还提供了其他方法

happens-before  规则



#### 哪些操作会建立happens-before规则

1 程序的顺序规则

2 volatile规则

3 传递性规则

4 synchronized监视器规则



## JUC工具包

### Lock

lock本质是一个接口，他定义了释放锁和获得锁的抽象方法。

实现类：

ReentrantLock:表示重入锁，他是唯一一个实现类Lock接口的类。重入锁指的是线程在获得锁之后，再次获得该锁就不需要阻塞，而实直接关联一次计数器加重入次数。释放锁减少重入次数。

ReentrantReadWriteLock：重入读写锁。他实现类ReadWriteLock接口，在这个类中维护了两个锁，一个是ReadLock一个是WriteLock，他们分别实现类Lock接口。  读写锁：读读不互斥，读和写互斥，写和写互斥。

stampedLock：是jdk8引入的锁机制，可以认为是读写锁的改进版本。如果大量线程存在会引发线程的饥饿，stampedLock是一种乐观锁的读策略，使得乐观锁完全不会阻塞线程。



**ReentrantLock和Synchronized都是重入锁**

重入锁的设计目的是避免线程死锁。



### ReentrantLock的实现原理

解决线程安全性

#### AQS是什么

在Lock中用到了一个同步队列AQS，全称AbstractQueuedSynchronizer，它是一个同步工具，也是Lock用来实现线程同步的核心组件。

##### AQS的两种功能

AQS功能分为两种：独占和共享。

独占锁：每次只能有一个线程持有锁。ReentrantLock就是独占方式实现互斥锁。

共享锁：允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock



#### AQS内部实现

AQS队列内部维护的是一个FIFO先进先出的双向队列。这种结构是每个数据结构都有两个指针，分别指向后继饥节点和前驱节点。每个Node都是由线程封装，当线程争抢锁失败后就会封装Node进入AQS队列中。当获取锁的线程释放锁之后，就会从队列中唤醒一个阻塞的节点（线程）。

#### 释放锁以及添加线程到队列的变化

添加线程：

1 新的线程封装成Node饥饿点追加到同步队列中，这只prev节点以及修改当前节点的前置节点的next节点指向自己。

2 通过cas将tail重新指向新的尾部节点。



释放锁：

1 修改head节点指向写一个获得锁的节点

2 新的获得锁的节点将prev指针指向null



#### ReentrantLock源码分析

![image-20210110195842089](\img\reentrantLock.png)



### 公平锁和非公平锁的区别

如果锁的获得顺序就应该符合请求的绝对时间顺序，也就是FIFO。

非公平锁在获得锁的时候，会先通过cas进行抢占，



## 线程工具类

### Condition工具类

condition是一个多线程协调通信的工具类。可以让某些线程一期等待某个条件，只有满足条件，线程才会被唤醒。



### CountDownLatch

countDownLatch是一个同步工具类，他允许一个或者多个线程一直等待，知道其他线程的操作执行完毕在执行，从命名可知道countdown是倒数的意思。

countdownlatch提供了两个方法，一个是countDown，一个是await。countdownlatch初始化的时候需要传入一个整数，这个整数倒数到0之前，调用await方法必须要等待，通过countDown来倒数。

```
public class CountDownLatchDemo01 extends Thread {
    static CountDownLatch countDownLatch=new CountDownLatch(1);//定义令牌数

    public static void main(String[] args) {
        for (int i=0;i<100;i++){
            new CountDownLatchDemo01().start();
        }
        countDownLatch.countDown();//减一
    }

    @Override
    public void run() {
        try{
            countDownLatch.await();//阻塞
        }catch (InterruptedException e){
            e.printStackTrace();
        }
        System.out.println("ThreadName"+Thread.currentThread().getName());
    }
}

```

### CountDownLatch源码分析

只关心两个方法，一个是await和countDown方法

countDown()方法每次调用就会将state减一，直到state=0。

await方法是一个阻塞方法 ，当state减到0的时候，await方法才会返回，await可以被多个线程调用，调用了await方法的线程阻塞在AQS的阻塞队列中，等待慢则state=0，将线程从队列中一个个唤醒。



countDownLatch内部写了一个Sybc并且继承AQS这个抽象类，重写了AQS的共享锁方法。



### Semaphore

semaphore就是信号量，semaphore可以控制同时访问的线程个数。通过acquire来获取一个许可，如果没有就等待。通过release释放一个许可。有点类似与限流

```
public class Service {
    private Semaphore semaphore=new Semaphore(2);//同一时间做多允许一个线程执行
    public void testMethod(){
        try {
            semaphore.acquire();// 使用掉一个许可，减法
            System.out.println(Thread.currentThread().getName()+"begin timer="+System.currentTimeMillis());
            Thread.sleep(5000);
            System.out.println(Thread.currentThread().getName()+"end timer"+System.currentTimeMillis());
            semaphore.release();//创建一个许可
        }catch (Exception e){
            System.out.println("线程"+Thread.currentThread().getName()+"进入了catch");
            e.fillInStackTrace();
        }

    }
}
```

availablePermits()返回此Semaphore对象中当前可用的许可数，

drainPermits()可获取并返回立即可用的所有许可个数，并且将可用许可置0。

方法getQueueLength()的作用是取得等待许可的线程个数。

方法hasQueuedThreads()的作用是判断有没有线程在等待这个许可。

Semaphore的构造方法后加参数位true为顺序执行。

方法tryAcquire()的使用无参方法tryAcquire()的作用是尝试地获得1个许可，如果获取不到则返回false，此方法通常与if语句结合使用，其具有无阻塞的特点。无阻塞的特点可以使线程不至于在同步处一直持续等待的状态，如果if语句判断不成立则线程会继续走else语句，程序会继续向下运行。

方法tryAcquire(int permits)的使用有参方法tryAcquire(int permits)的作用是尝试地获得x个许可，如果获取不到则返回false。

方法tryAcquire(long timeout, TimeUnit unit)的使用有参方法tryAcquire(int long timeout, TimeUnit unit)的作用是在指定的时间内尝试地获得1个许可，如果获取不到则返回false。

### Semaphore源码分析

从 Semaphore 的功能来看，我们基本能猜测到它的底层实现一定是基于 AQS 的共享锁，因为需要实现多个线程共享一个令牌池
创建 Semaphore 实例的时候，需要一个参数 permits，这个基本上可以确定是设置给 AQS 的 state 的，然后每个线程调用 acquire 的时候，执行 state = state - 1，release 的时候执行 state = state + 1，当然， acquire 的时候，如果 state = 0，说明没有资源了，需要等待其他线程 release。
Semaphore 分公平策略和非公平策略  



### CyclicBarrier

**是周期、循环的意思**

门栅、关卡和障碍的意思。类CyclicBarrier不仅有CountDownLatch所具有的功能，还可以实现屏障等待的功能，也就是阶段性同步，它在使用上的意义在于可以循环地实现线程要一起做任务的目标，而不是像类CountDownLatch一样，仅仅支持一次线程与同步点阻塞的特性

够数就发车

CyclicBarrier的计数是加法操作。

方法getNumberWaiting()进行实验，该方法的作用是获得有几个线程已经到达屏障点。

方法isBroken()查询此屏障是否处于损坏状态。

方法await(long timeout, TimeUnit unit)的功能是如果在指定的时间内达到parties的数量，则程序继续向下运行，否则如果出现超时，则抛出TimeoutException异常。

方法getNumberWaiting()的作用是有几个线程已经到达屏障点。方法getParties()的作用是取得parties个数。

方法reset()的作用是重置屏障。 	

```
public class MyThread extends Thread {
    private CyclicBarrier cbRef;
    public MyThread(CyclicBarrier cbRef){
        super();
        this.cbRef=cbRef;
    }
    public void run(){
        try {
            Thread.sleep((int)Math.random()*10000);
            System.out.println(Thread.currentThread().getName()+"到了"+System.currentTimeMillis());
            cbRef.await();
            System.out.println(Thread.currentThread().getName()+"结束");
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}
```

```
public class Run {
    public static void main(String[] args) {
        CyclicBarrier cyclicBarrier=new CyclicBarrier(2, new Runnable() {
            public void run() {
                System.out.println("全部到了");
            }
        });
        MyThread[] myThreads=new MyThread[6];
        for (int i=0;i<myThreads.length;i++){
            myThreads[i] =new MyThread(cyclicBarrier);
            myThreads[i].start();
        }
    }
}
```

### 实现原理

CyclicBarrier 相比 CountDownLatch 来说，要简单很多，源码实现是基于 ReentrantLock 和 Condition 的组合使用。

### Exchanger

可以使2个线程之间传输数据，它比生产者/消费者模式使用的wait/notify要更加方便.

方法exchange()阻塞的特性类Exchanger中的exchange()方法具有阻塞的特色，也就是此方法被调用后等待其他线程来取得数据，如果没有其他线程取得数据，则一直阻塞等待。

```
public class ThreadA extends Thread {
    private Exchanger<String> exchanger;
    public ThreadA(Exchanger<String> exchanger){
        super();
        this.exchanger=exchanger;
    }
    public void run(){
        try {
            System.out.println("线程A中得到线程B的值"+exchanger.exchange("中国人A"));
            System.out.println("A end");
        }catch (Exception e){
            e.fillInStackTrace();
        }
    }
}
```

```
public class ThreadB extends Thread {
    private Exchanger<String> exchanger;
    public ThreadB(Exchanger exchanger){
        super();
        this.exchanger=exchanger;
    }
    public void run(){
        try {
            System.out.println("线程B获取线程A的值="+exchanger.exchange("中国人B"));
        }catch (Exception e){
            e.getStackTrace();
        }
    }
}
```

```
public class Run {
    public static void main(String[] args) {
        Exchanger<String> exchanger=new Exchanger<String>();
        ThreadA a=new ThreadA(exchanger);
        ThreadB b=new ThreadB(exchanger);
        a.start();
        b.start();
        System.out.println("main end");
    }
}
```



## ConcurrentHashMap

并发安全的集合

是map的派生类。详解put和get方法。

### 源码分析

jdk1.7 ConcurrentHashMap 由一个个Segment组成，Segment是一个数组，继承ReentrantLock加锁。

![image-20210111231214756](\img\ConcurrentHashMap1.png)

默认情况下，理论上可以同时支持16个线程并发写入。

### jdk1.8版本

1 取消了segment分段设计，直接使用Node数组来存储数据，并且采用Node数组元素作为锁来实现每一行数据进行加锁来进一步减少并发冲突的概率。

2 原来数组+单链表的数据结构，变更为数组+单向链表+红黑树的结构。

​	红黑树防止链表过长，队列长度超过8个，单链表查询节点时间复杂度O(n)  红黑树查询的时间复杂度O(logN)

#### put方法第一阶段

```
public V put(K key, V value) {
        return putVal(key, value, false);
    }
```

```
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode()); //计算hash值
    int binCount = 0; //用来记录链表长度
    for (Node<K,V>[] tab = table;;) {//当线程出现竞争不断自旋
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0) //如果数组长度0
            tab = initTable();  //初始化数组
            //通过hash对应下标取节点，以volatile读方式读
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
        	//如果下标返回节点为空，直接通过cas封装node插入，cas失败进入下一次循环
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        
        
        
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```



#### 数组初始化initTable

sizeCtl 这个标志是Node数组初始化或者扩容的控制位标识，负数代表正在进行初始化或者扩容

-1 代表正在初始化

-N 代表N-1由个线程正在进行扩容，

0 代表Node数组还没有初始化

正数代表初始化或者下一次扩容的大小

```
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) < 0) //被其他线程抢占初始化操作，则让出cpu时间片
            Thread.yield(); // lost initialization race; just spin
            //cas操作，替换sizeCtl为-1 当前线程抢占到初始化资格
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                	//初始容量16
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    //构造，传入长度16
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    //将这个数组赋值给table
                    table = tab = nt;
                    // 计算下一次扩容的大小 实际上是当前容量的0.75
                    sc = n - (n >>> 2);
                }
            } finally {
            //16*0.75=12
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

#### tabAt 根据下标取值

```
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}
```

getObjectVolatile 可见性。



#### put方法第二阶段

addCount 来增加ConcurrentHashMap的元素个数，有可能触发扩容操作。

传递两个参数，1L和binCount（链表长度）

```
private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;
    //1 如果数组为空，通过cas操作修改baseCount变量，原子类累加操作
    //2 如果cas失败，通过CounterCell来记录
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        boolean uncontended = true; //是否冲突标识，默认没有冲突
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended =
              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            fullAddCount(x, uncontended);
            return;
        }
        if (check <= 1)
            return;
        s = sumCount();
    }
    //扩容判断
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            if (sc < 0) {
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
```